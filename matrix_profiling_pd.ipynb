{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Small Test (10000 x 100) ---\n",
      "DataFrame shapes:\n",
      "- row-major: (10000, 100)\n",
      "- col-major: (100, 10000)\n",
      "\n",
      "=== Multiple Operations Profiling ===\n",
      "row-major sum                 : 0.001716 ± 0.001589 seconds (mean ± std over 100 runs)\n",
      "col-major sum                 : 0.001296 ± 0.000115 seconds (mean ± std over 100 runs)\n",
      "row-major mean                : 0.002397 ± 0.000142 seconds (mean ± std over 100 runs)\n",
      "col-major mean                : 0.002023 ± 0.000114 seconds (mean ± std over 100 runs)\n",
      "row-major std                 : 0.023837 ± 0.053554 seconds (mean ± std over 100 runs)\n",
      "col-major std                 : 0.016518 ± 0.027746 seconds (mean ± std over 100 runs)\n",
      "row-major transpose           : 0.000074 ± 0.000050 seconds (mean ± std over 100 runs)\n",
      "col-major transpose           : 0.000758 ± 0.000048 seconds (mean ± std over 100 runs)\n",
      "row-major reshape             : 0.000019 ± 0.000008 seconds (mean ± std over 100 runs)\n",
      "col-major reshape             : 0.000017 ± 0.000002 seconds (mean ± std over 100 runs)\n",
      "row-major write to txt        : 0.187158 ± 0.013183 seconds (mean ± std over 10 runs)\n",
      "col-major write to txt        : 0.304017 ± 0.016877 seconds (mean ± std over 10 runs)\n",
      "row-major read from txt       : 0.092501 ± 0.031178 seconds (mean ± std over 10 runs)\n",
      "col-major read from txt       : 0.284309 ± 0.090559 seconds (mean ± std over 10 runs)\n",
      "\n",
      "\n",
      "\n",
      "--- Medium Test (100000 x 500) ---\n",
      "DataFrame shapes:\n",
      "- row-major: (100000, 500)\n",
      "- col-major: (500, 100000)\n",
      "\n",
      "=== Multiple Operations Profiling ===\n",
      "row-major sum                 : 0.049670 ± 0.004704 seconds (mean ± std over 100 runs)\n",
      "col-major sum                 : 0.056343 ± 0.006052 seconds (mean ± std over 100 runs)\n",
      "row-major mean                : 0.072309 ± 0.004515 seconds (mean ± std over 100 runs)\n",
      "col-major mean                : 0.079529 ± 0.005694 seconds (mean ± std over 100 runs)\n",
      "row-major std                 : 1.051843 ± 2.432833 seconds (mean ± std over 100 runs)\n",
      "col-major std                 : 0.589445 ± 0.013323 seconds (mean ± std over 100 runs)\n",
      "row-major transpose           : 0.000093 ± 0.000034 seconds (mean ± std over 100 runs)\n",
      "col-major transpose           : 0.006565 ± 0.000462 seconds (mean ± std over 100 runs)\n",
      "row-major reshape             : 0.000016 ± 0.000008 seconds (mean ± std over 100 runs)\n",
      "col-major reshape             : 0.000014 ± 0.000002 seconds (mean ± std over 100 runs)\n",
      "row-major write to txt        : 8.447664 ± 0.120095 seconds (mean ± std over 10 runs)\n",
      "col-major write to txt        : 66.580490 ± 0.722138 seconds (mean ± std over 10 runs)\n",
      "row-major read from txt       : 4.959075 ± 2.895469 seconds (mean ± std over 10 runs)\n",
      "col-major read from txt       : 34.934332 ± 0.668331 seconds (mean ± std over 10 runs)\n",
      "\n",
      "\n",
      "\n",
      "--- Large Test (1000000 x 500) ---\n",
      "DataFrame shapes:\n",
      "- row-major: (1000000, 500)\n",
      "- col-major: (500, 1000000)\n",
      "\n",
      "=== Multiple Operations Profiling ===\n",
      "row-major sum                 : 0.498118 ± 0.049909 seconds (mean ± std over 100 runs)\n",
      "col-major sum                 : 0.572226 ± 0.030478 seconds (mean ± std over 100 runs)\n",
      "row-major mean                : 0.709371 ± 0.049020 seconds (mean ± std over 100 runs)\n",
      "col-major mean                : 0.738514 ± 0.043386 seconds (mean ± std over 100 runs)\n",
      "row-major std                 : 8.035312 ± 14.944555 seconds (mean ± std over 100 runs)\n",
      "col-major std                 : 6.559278 ± 1.362394 seconds (mean ± std over 100 runs)\n",
      "row-major transpose           : 0.000103 ± 0.000038 seconds (mean ± std over 100 runs)\n",
      "col-major transpose           : 0.068022 ± 0.001824 seconds (mean ± std over 100 runs)\n",
      "row-major reshape             : 0.000017 ± 0.000012 seconds (mean ± std over 100 runs)\n",
      "col-major reshape             : 0.000016 ± 0.000003 seconds (mean ± std over 100 runs)\n",
      "row-major write to txt        : 82.842018 ± 2.098016 seconds (mean ± std over 10 runs)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "def generate_count_df(rows, cols, min_val=0, max_val=100, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    data = rng.integers(min_val, max_val + 1, size=(rows, cols))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def write_df_to_txt(df, filename=\"temp_df.txt\"):\n",
    "    df.to_csv(filename, sep='\\t', header=False, index=False)\n",
    "\n",
    "def read_df_from_txt(filename=\"temp_df.txt\"):\n",
    "    return pd.read_csv(filename, sep='\\t', header=None)\n",
    "\n",
    "def profile_pandas_operations(df_row, df_col, label=\"DataFrame\", n_iter=100, filename_prefix=\"temp_df\"):\n",
    "    print(f\"--- {label} Test ({df_row.shape[0]} x {df_row.shape[1]}) ---\")\n",
    "    print(\"DataFrame shapes:\")\n",
    "    print(f\"- row-major: {df_row.shape}\")\n",
    "    print(f\"- col-major: {df_col.shape}\")\n",
    "\n",
    "    operations = {\n",
    "        \"row-major sum\": lambda: df_row.sum(axis=1),\n",
    "        \"col-major sum\": lambda: df_col.sum(axis=0),\n",
    "        \"row-major mean\": lambda: df_row.mean(axis=1),\n",
    "        \"col-major mean\": lambda: df_col.mean(axis=0),\n",
    "        \"row-major std\": lambda: df_row.std(axis=1),\n",
    "        \"col-major std\": lambda: df_col.std(axis=0),\n",
    "        \"row-major transpose\": lambda: df_row.T,\n",
    "        \"col-major transpose\": lambda: df_col.T,\n",
    "        \"row-major reshape\": lambda: pd.DataFrame(df_row.values.reshape(-1, 50)),\n",
    "        \"col-major reshape\": lambda: pd.DataFrame(df_col.values.reshape(-1, 50)),\n",
    "        \"row-major write to txt\": lambda: write_df_to_txt(df_row, f\"{filename_prefix}_row.txt\"),\n",
    "        \"col-major write to txt\": lambda: write_df_to_txt(df_col, f\"{filename_prefix}_col.txt\"),\n",
    "        \"row-major read from txt\": lambda: read_df_from_txt(f\"{filename_prefix}_row.txt\"),\n",
    "        \"col-major read from txt\": lambda: read_df_from_txt(f\"{filename_prefix}_col.txt\"),\n",
    "    }\n",
    "\n",
    "    print(\"\\n=== Multiple Operations Profiling ===\")\n",
    "    for op_name, operation in operations.items():\n",
    "        times = []\n",
    "        current_iter = n_iter if \"read\" not in op_name and \"write\" not in op_name else 10\n",
    "        for _ in range(current_iter):\n",
    "            start = time.perf_counter()\n",
    "            operation()\n",
    "            end = time.perf_counter()\n",
    "            times.append(end - start)\n",
    "        print(f\"{op_name:30s}: {np.mean(times):.6f} ± {np.std(times):.6f} seconds (mean ± std over {current_iter} runs)\")\n",
    "\n",
    "    for suffix in [\"row\", \"col\"]:\n",
    "        file = f\"{filename_prefix}_{suffix}.txt\"\n",
    "        if os.path.exists(file):\n",
    "            os.remove(file)\n",
    "\n",
    "def run_all_profiles():\n",
    "    sizes = {\n",
    "        \"Small\": (10_000, 100),\n",
    "        \"Medium\": (100_000, 500),\n",
    "        \"Large\": (1_000_000, 500),\n",
    "    }\n",
    "    for label, (n_row, n_col) in sizes.items():\n",
    "        df_row = generate_count_df(n_row, n_col)\n",
    "        df_col = generate_count_df(n_col, n_row)\n",
    "        profile_pandas_operations(df_row, df_col, label=label, filename_prefix=f\"temp_{label.lower()}_df\")\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "run_all_profiles()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# legacy code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_col = 10000\n",
    "n_row = 10000\n",
    "data_rows = pd.DataFrame(np.random.rand(n_col, n_row))\n",
    "\n",
    "start_time = time.time()\n",
    "# Compute std for each feature (row-wise)\n",
    "std_rows = data_rows.std(axis=1)\n",
    "print(std_rows.shape)\n",
    "elapsed_rows = time.time() - start_time\n",
    "\n",
    "print(f\"Case 1 (features as rows): {elapsed_rows:.4f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
